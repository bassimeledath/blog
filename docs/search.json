[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Articles",
    "section": "",
    "text": "How We Built Ask Priya\n\n\n\n\n\n\n\nLLMs\n\n\nRAG\n\n\n\n\nA Gen AI U.S. Immigration Assistant\n\n\n\n\n\n\nMar 25, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Le Khan Academie lets you generate on demand Khan Academy style videos for any topic using Gen AI, specifically with a finetuned Mistral 8x7B model.\nLe Khan Academie allows users to input queries (e.g., ‚ÄúHow does the distributive property work?‚Äù). Then Mistral large rewrites this query with more details on what the manim animation should include. This rewritten prompt is then passed into the finetuned Mistral model. Generates a Khan Academy-style video explaining and visualizing the concept with:\n\nAnimation created with finetuned Mixtral 8x7B on Fireworks AI that generates python code using manim animation library.\nNarration by a voice clone of Sal Khan, synchronized with the animation for a brief lecture.\n\nHere is a video demonstration - Link"
  },
  {
    "objectID": "projects.html#le-khan-academie",
    "href": "projects.html#le-khan-academie",
    "title": "Projects",
    "section": "",
    "text": "Le Khan Academie lets you generate on demand Khan Academy style videos for any topic using Gen AI, specifically with a finetuned Mistral 8x7B model.\nLe Khan Academie allows users to input queries (e.g., ‚ÄúHow does the distributive property work?‚Äù). Then Mistral large rewrites this query with more details on what the manim animation should include. This rewritten prompt is then passed into the finetuned Mistral model. Generates a Khan Academy-style video explaining and visualizing the concept with:\n\nAnimation created with finetuned Mixtral 8x7B on Fireworks AI that generates python code using manim animation library.\nNarration by a voice clone of Sal Khan, synchronized with the animation for a brief lecture.\n\nHere is a video demonstration - Link"
  },
  {
    "objectID": "projects.html#guided-sprout",
    "href": "projects.html#guided-sprout",
    "title": "Projects",
    "section": "Guided Sprout",
    "text": "Guided Sprout\n\n\n\nApp\n\n\nGuided Sprout uses AI to personalize education. Our multimodal platform grades exams, provides tailored student feedback, and recommends targeted resources for improvement.\nWe use 5 OpenAI models to do so:\n\nGPT-4V: Transcribes text from paper-based exams.\nGPT-3.5 Turbo: Used as the router model to determine whether an answer is correct. If incorrect, passes the evaluation task to GPT-4.\nGPT-4: Uses Chain of Thought reasoning to give student highly individualized feedback.\nText-to-speech: Converts summarized feedback to audio.\nText-embedding-3-small: Embeds math textbook content.\n\nWatch video demonstration here: Link\n\n\n\nSystem Diagram"
  },
  {
    "objectID": "projects.html#uncle-sam-tax",
    "href": "projects.html#uncle-sam-tax",
    "title": "Projects",
    "section": "Uncle Sam Tax",
    "text": "Uncle Sam Tax\n\n\n\nApp\n\n\nFiling taxes should be simple, especially for the 100M+ Americans who have the simple scenario of just one income source. UncleSamTax solves this by making filing taxes as simple as 1-2-3. How? We ask the user to upload the past year‚Äôs forms. We then use GPT-Vision to read the info from the forms and use GPT-4 to calculate values for the next year‚Äôs tax return form. And Voila! The user has a filled and prepared tax form that they submit to the government (aka UncleSam). By making doing taxes automated and simple, we are different from other complicated tax products (for every complicated tax scenario) as we are simple taxes for simple scenarios.\nUncle Sam Tax was built using Python, GPT-4, GPT-Vision, Trulens, Portkey, Streamlit etc. Uncle Sam Tax, as a proof of concept, won first place at the GPT hackathon in San Francisco. Our team then decided to go ahead and impelment it for the GPT-4 Powered App Creation Hackathon."
  },
  {
    "objectID": "projects.html#ab-agent",
    "href": "projects.html#ab-agent",
    "title": "Projects",
    "section": "AB Agent",
    "text": "AB Agent\n\nAB Agent automates two parts of the A/B testing workflow using Generative AI:\nDesign\nThe design phase of A/B testing is crucial for setting the stage for meaningful insights. AB Agent simplifies this process in three steps:\n\nUnderstanding User Instructions: Initially, AB Agent takes a user‚Äôs natural language instruction to set up an experiment. For example, a user might say, ‚ÄúDesign an A/B test to test a UI change where the metric to increase is browsing time. We want the minimum effect to be 10% and we want to be 95% confident in the results.‚Äù\nRephrasing Queries: The instruction is then passed through the mixtral-8x7b-instruct model, which rephrases the user query into a more statistically oriented format. This step ensures that the setup is aligned with statistical best practices and clarifies the experiment‚Äôs objectives.\nFunction Calling for Experiment Design: Subsequently, the refined query is passed to firefunction-v1. This component ideally calls a sample size calculator among other tools to determine the necessary sample size and other critical details for designing the A/B test effectively.\n\nInference\nThe inference phase is where the results of the A/B test are interpreted to make informed decisions:\n\nInterpreting Results: For interpreting the outcomes of an A/B test, AB Agent employs a function-calling model that uses a t-test calculator and other functions. This approach facilitates a robust analysis of the results.\nMaking Decisions: Based on this analysis, AB Agent makes a go/no-go decision on whether to implement feature B. This decision-making process is backed by statistical evidence, ensuring that changes are made with confidence in their impact.\n\nBuilt using Python, React, Fireworks etc. AB Agent was a finalist project at the OSS Functional Calling Hackathon."
  },
  {
    "objectID": "projects.html#jobocomplete",
    "href": "projects.html#jobocomplete",
    "title": "Projects",
    "section": "JoboComplete",
    "text": "JoboComplete\n\nManually inputting the same information like name, email, LinkedIn URL etc. over and over again for each application is a dreadful experience. JoboComplete, a Chrome extension, that automates input filling using LlamaIndex‚Äôs RAG capabilities, which has information about your resume.\nBuilt using Javascript, Python, FastAPI, LlamaIndex etc. JoboComplete won Honorable Mention at the LlamaIndex RAG hackathon!"
  },
  {
    "objectID": "projects.html#ask-priya",
    "href": "projects.html#ask-priya",
    "title": "Projects",
    "section": "Ask Priya",
    "text": "Ask Priya\n\nAsk Priya is an LLM RAG chatbot that answers questions about US immigration using Google‚Äôs chat bison model that is fed both the user question and retrieved immigration documents from a vector store. The vector store is built using Llama-index and the documents are scraped webpages from the USCIS website.\nAsk Priya performs way better than Ask Emma, the existing solution used by USCIS. Ask Priya also won first place in the Truera Gen AI hackathon.\nBuilt using Python, Llama-index, VertexAI, OpenAI, Trulens, Streamlit etc."
  },
  {
    "objectID": "projects.html#gemini-hire",
    "href": "projects.html#gemini-hire",
    "title": "Projects",
    "section": "Gemini Hire",
    "text": "Gemini Hire\n\nGemini Hire makes applying to jobs way easier using Gen AI. It parses your resume more effectively than Workday using Google‚Äôs gemini vision pro into a json file. That json file, along with a user pasted job description, is then fed into 3 sub applications - a cover letter generator, interview questions generator and a skills gap analysis generator. These sub applications are mainly driven by Gemini Pro‚Äôs text model. Evaluation is done using Trulens and OpenAI‚Äôs API. GeminiHire won second place at the Gemini AI Hackathon!\nBuilt using Python, Gemini Vision Pro, OpenAI, Trulens, HuggingFace, Gradio etc."
  },
  {
    "objectID": "projects.html#sarimacv",
    "href": "projects.html#sarimacv",
    "title": "Projects",
    "section": "SarimaCV",
    "text": "SarimaCV\n\nSarimaCV is a python package that does cross validation for SARIMA models in a distributed manner. In my time series class, I was frustrated with having to do cross validation iteratively one condition at a time. So I quickly hacked together a package that does this in a distributed manner."
  },
  {
    "objectID": "projects.html#data-science-new-tab-chrome-application",
    "href": "projects.html#data-science-new-tab-chrome-application",
    "title": "Projects",
    "section": "Data Science New Tab Chrome Application",
    "text": "Data Science New Tab Chrome Application\n\nNew Tab application for Chrome with quick access to University of San Francisco pages like MyUSF, calendar, one card etc. Additionally keep up with recent papers and blogs in AI and latest events in San Francisco (updated daily). Also has a to-do list.\nBuilt using Python, React, Firebase, TailwindCSS, Chrome storage API etc."
  },
  {
    "objectID": "posts/ask_priya_v1/post.html",
    "href": "posts/ask_priya_v1/post.html",
    "title": "How We Built Ask Priya",
    "section": "",
    "text": "US Immigration is complicated\nThere are millions of people looking to either visit, move to or reside in the US. And in that pursuit, they are confronted with the US immigration system overseen by the USCIS (United States Citizenship and Immigration Services).\nAnd as anyone will tell you, dealing with the USCIS is a nightmare. The forms are complicated, the instructions are confusing and the wait times are long. And if you make a mistake, you could be denied entry or worse, deported.\nThe abundance of policies, forms and instructions are overwhelming, especially for native English speakers.\n\n\nThe current solution\nUSCIS‚Äôs attempt at a solution is ‚ÄòAsk Emma‚Äô which, in their words, is a ‚Äúcomputer-generated virtual assistant who can answer your questions and even take you to the right spot on our website.‚Äù\nBut Ask Emma is not very helpful. It is not very smart and it is not very human. It‚Äôs responses are quite formulaic, with users typically picking from a menu of choices. Here you can see Ask Emma not knowing an answer to a question that is very common among international students.\n\nFurthermore, Ask Emma is not very accessible as it is only available in English and Spanish.\n\n\nThe better solution - Ask Priya\nSo you have this large body of textual information on immigration services that is publicly available on the USCIS website, and a poorly perofrming chatbot that is not very accessible. How do we make this information more accessible?\nEnter Retrieval Augmented Generation (RAG) models. RAG models are a combination of a retrieval model and a generation model. The retrieval model is used to retrieve relevant passages from the USCIS website, and the generation model is used to generate an answer to the question based on the retrieved passages and the user‚Äôs question.\nSo a few compadres and I built Ask Priya.\n\n\n\nSystems design\nSo how does Ask Priya work under the hood? At a high level, it takes a user‚Äôs question, embeds it using openai‚Äôs ada-002 model, then similar documents are retrieved from the llama-index vector store, and then the LLM, Vertex AI Chat Bison, is given both the question and the retrieved documents to generate an answer, which is then returned to the user. The vector store here contains embeddings of all the documents (web pages) on the USCIS website.\nAnd this pipeline‚Äôs performance is evaluated using Trulens Eval which I will cover in detail in the next section.\n\n\n\nEvaluation\nSo we have a working RAG model, but how do we know if it is performing well? To answer that, we first needed a baseline performance for comparison.\nSo we used the trulens package to establish an ‚Äòanswer relevance‚Äô score for Ask Emma. For the unacquainted, trulens is a package that essentially lets you easily use LLMs to evaluate LLM performance. It works by prompting another LLM, known as an ‚Äòevaluator,‚Äô to assess the performance of your model. This assessment typically involves scoring the original model‚Äôs responses based on criteria such as ‚Äòanswer relevance,‚Äô which measures how closely the LLM‚Äôs response aligns with the user‚Äôs query.\nThe difference in answer relevance between Ask Emma (0.33) and Ask Priya (0.99) is quite stark. This means that Ask Priya‚Äôs is actually answering the question asked by the user. Of course, this is not indicative of whether the answer is actually correct, but it is a great start.\n\n\n\nNext steps\nThe proof of concept for Ask Priya won first place at the Truera Hackathon and we are excited to continue working on it. Some of the next steps include:\n\nTry further advanced retrieval strategies to improve the groundedness metric\nFurther prompt engineering to improve answer quality\nMigrate to google cloud deployment\nAdd more trulens feedback functions\n\nAnd more! Excited for the progression of Ask Priya!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hi, I‚Äôm Bassim üëãüèæ",
    "section": "",
    "text": "class AboutBassim: \n    def __init__(self):\n        self.occupation = 'Machine Learning Engineer'\n        self.skills = (\n            'Python',\n            'Machine Learning',\n            'A/B testing',\n            'Generative AI'\n        )\n        self.hobbies = (\n            'üèãÔ∏è‚Äç‚ôÇÔ∏è Powerlifting',\n            'üå∂Ô∏è Eating spicy food',\n            'üèì Playing pickleball'\n        )\n        self.current_favorite_music_artists = (\n            'Takeshi's Cashew',\n            'Etran de L`A√Ør',\n            'French79'\n        )\n        self.fun_fact = 'I grew up in Dubai!'"
  }
]